{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a4fcddf",
   "metadata": {},
   "source": [
    "# Evaluate arbitrage opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ffb1b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import os\n",
    "import glob\n",
    "import tarfile\n",
    "import bz2\n",
    "import betfairlightweight\n",
    "from betfairlightweight import filters\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "from unittest.mock import patch\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03866f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633be809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this certs path to wherever you're storing your certificates\n",
    "certs_path = '/Users/guillaume_baquiast/Documents/tmp'\n",
    "\n",
    "# Change these login details to your own\n",
    "my_username = \"your_email\"\n",
    "my_password = \"your_password\"\n",
    "my_app_key = \"your_app_key\"\n",
    "\n",
    "trading = betfairlightweight.APIClient(username=my_username,\n",
    "                                       password=my_password,\n",
    "                                       app_key=my_app_key,\n",
    "                                       certs=certs_path)\n",
    "\n",
    "listener = betfairlightweight.StreamListener(max_latency=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d2db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading from tar and extracting files\n",
    "def load_markets(file_paths: List[str]):\n",
    "    for file_path in file_paths:\n",
    "        if os.path.isdir(file_path):\n",
    "            for path in glob.iglob(file_path + '**/**/*.bz2', recursive=True):\n",
    "                f = bz2.BZ2File(path, 'rb')\n",
    "                yield f\n",
    "                f.close()\n",
    "        elif os.path.isfile(file_path):\n",
    "            ext = os.path.splitext(file_path)[1]\n",
    "            # iterate through a tar archive\n",
    "            if ext == '.tar':\n",
    "                with tarfile.TarFile(file_path) as archive:\n",
    "                    for file in archive:\n",
    "                        yield bz2.open(archive.extractfile(file))\n",
    "            # or a zip archive\n",
    "            elif ext == '.zip':\n",
    "                with zipfile.ZipFile(file_path) as archive:\n",
    "                    for file in archive.namelist():\n",
    "                        yield bz2.open(archive.open(file))\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaaa0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_proba_through_time(\n",
    "    df_game: pd.DataFrame,\n",
    "    df_game_filter: pd.Series = None,\n",
    "    date_time_start_game: str = None,\n",
    "    x_lim_hours_start_game: Tuple = (5, 2),\n",
    "    y_lim: Tuple = (0, 1.1),\n",
    "    title: str = None,\n",
    "    plot_game_time_limits: bool = True,\n",
    "    goal_times: List = [],\n",
    "    arbitrage_bound: int = None,\n",
    "):\n",
    "    xlim = None\n",
    "    if x_lim_hours_start_game:\n",
    "        xlim = (\n",
    "            np.datetime64(date_time_start_game) - np.timedelta64(x_lim_hours_start_game[0], 'h'),\n",
    "            np.datetime64(date_time_start_game) + np.timedelta64(x_lim_hours_start_game[1], 'h'),\n",
    "        )\n",
    "\n",
    "    if df_game_filter is None:\n",
    "        df_game_filter = [True] * df_game.shape[0]\n",
    "    \n",
    "    df_game[df_game_filter].plot(\n",
    "        x=\"publish_time\",\n",
    "        y=\"proba\",\n",
    "        xlim=xlim,\n",
    "        ylim=y_lim,\n",
    "        figsize=(15, 7)\n",
    "    )\n",
    "\n",
    "    if plot_game_time_limits:\n",
    "        plt.axvline(x=np.datetime64(date_time_start_game), color=\"orange\", label=\"game_in\")\n",
    "        plt.axvline(x=np.datetime64(date_time_start_game) + np.timedelta64(45+15+45, 'm'), color=\"orange\")\n",
    "\n",
    "\n",
    "    if goal_times:\n",
    "        for goal_time in goal_times:\n",
    "            if goal_time > 45:\n",
    "                goal_time += 15\n",
    "            plt.axvline(x=np.datetime64(date_time_start_game) + np.timedelta64(goal_time, 'm'), color=\"grey\",\n",
    "                        linestyle=\"--\")\n",
    "\n",
    "    if arbitrage_bound:\n",
    "        plt.axhline(y=1, color=\"red\")\n",
    "        plt.axhline(y=1-arbitrage_bound, color=\"red\", linestyle=\"--\")\n",
    "        plt.axhline(y=1+arbitrage_bound, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48d9306",
   "metadata": {},
   "source": [
    "# Load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff8a44b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata = pd.read_csv(\"/Users/guillaume_baquiast/Documents/tmp/champions_league_metadata.csv\")\n",
    "\n",
    "# Guess time of start of game\n",
    "df_metadata[\"market_time\"] = pd.to_datetime(df_metadata[\"date\"] + \" 20:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da6495f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_id</th>\n",
       "      <th>market_time</th>\n",
       "      <th>open_date</th>\n",
       "      <th>path</th>\n",
       "      <th>date</th>\n",
       "      <th>league</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barcelona v Paris St-G</td>\n",
       "      <td>30186199.0</td>\n",
       "      <td>2021-02-16 20:00:00</td>\n",
       "      <td>16/02/2021 20:00</td>\n",
       "      <td>/Users/guillaume_baquiast/Documents/tmp/data/B...</td>\n",
       "      <td>16/02/2021</td>\n",
       "      <td>Champions League</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RB Leipzig v Liverpool</td>\n",
       "      <td>30186224.0</td>\n",
       "      <td>2021-02-16 20:00:00</td>\n",
       "      <td>16/02/2021 20:00</td>\n",
       "      <td>/Users/guillaume_baquiast/Documents/tmp/data/B...</td>\n",
       "      <td>16/02/2021</td>\n",
       "      <td>Champions League</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               event_name    event_id         market_time         open_date  \\\n",
       "0  Barcelona v Paris St-G  30186199.0 2021-02-16 20:00:00  16/02/2021 20:00   \n",
       "1  RB Leipzig v Liverpool  30186224.0 2021-02-16 20:00:00  16/02/2021 20:00   \n",
       "\n",
       "                                                path        date  \\\n",
       "0  /Users/guillaume_baquiast/Documents/tmp/data/B...  16/02/2021   \n",
       "1  /Users/guillaume_baquiast/Documents/tmp/data/B...  16/02/2021   \n",
       "\n",
       "             league country  \n",
       "0  Champions League  Europe  \n",
       "1  Champions League  Europe  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3ff141",
   "metadata": {},
   "source": [
    "# Load game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bef0c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_game_data(market_paths: List) -> Dict:\n",
    "    data_dict = {\n",
    "        \"event_name\": [],\n",
    "        \"event_id\": [],\n",
    "        \"market_type\": [],\n",
    "        \"market_time\": [],\n",
    "        \"open_date\": [],\n",
    "        \"market_id\": [],\n",
    "        \"publish_time\": [],\n",
    "        \"runner_name\": [],\n",
    "        \"ltp\": [],\n",
    "        \"total_matched\": [],\n",
    "        \"in_play\": [],\n",
    "    }\n",
    "\n",
    "    for file_obj in load_markets(market_paths):\n",
    "        stream = trading.streaming.create_historical_generator_stream(\n",
    "            file_path=file_obj,\n",
    "            listener=listener,\n",
    "        )\n",
    "\n",
    "        with patch(\"builtins.open\", lambda f, _: f):   \n",
    "            gen = stream.get_generator()\n",
    "\n",
    "            for market_books in gen():\n",
    "                for market_book in market_books:\n",
    "                    for runner_idx in range(len(market_book.runners)):\n",
    "                        data_dict[\"event_name\"].append(market_book.market_definition.event_name)\n",
    "                        data_dict[\"event_id\"].append(market_book.market_definition.event_id)\n",
    "                        data_dict[\"market_type\"].append(market_book.market_definition.market_type)\n",
    "                        data_dict[\"market_time\"].append(market_book.market_definition.market_time)\n",
    "                        data_dict[\"open_date\"].append(market_book.market_definition.open_date)\n",
    "                        data_dict[\"market_id\"].append(market_book.market_id)\n",
    "                        data_dict[\"publish_time\"].append(market_book.publish_time)\n",
    "                        data_dict[\"runner_name\"].append(market_book.market_definition.runners[runner_idx].name)\n",
    "                        data_dict[\"ltp\"].append(market_book.runners[runner_idx].last_price_traded)\n",
    "                        data_dict[\"total_matched\"].append(market_book.runners[runner_idx].total_matched)\n",
    "                        data_dict[\"in_play\"].append(market_book.inplay)\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def preprocess_game_data(data_dict: Dict) -> pd.DataFrame:\n",
    "    # Create dataframe from data dict\n",
    "    df_game = pd.DataFrame(data_dict).drop_duplicates()\n",
    "\n",
    "    # Ensure to have all information at each tick\n",
    "    df_time_ids = df_game[[\"publish_time\"]].drop_duplicates()\n",
    "    df_market_ids = df_game[[\"market_type\", \"runner_name\"]].drop_duplicates()\n",
    "\n",
    "    df_time_ids[\"key\"] = 1\n",
    "    df_market_ids[\"key\"] = 1\n",
    "\n",
    "    df_ids = df_time_ids.merge(df_market_ids, on=\"key\", how=\"inner\").drop(columns=\"key\")\n",
    "\n",
    "    df_game = df_ids.merge(df_game, on=[\"publish_time\", \"market_type\", \"runner_name\"], how=\"left\")\n",
    "\n",
    "    # Sort and fill na\n",
    "    df_game = df_game.sort_values([\"market_type\", \"runner_name\", \"publish_time\"])\n",
    "    df_game[\"ltp\"] = df_game.groupby([\"market_type\", \"runner_name\"])[\"ltp\"].fillna(method=\"ffill\")\n",
    "\n",
    "    # Add odd and proba\n",
    "    df_game[\"odd\"] = df_game[\"ltp\"] - 1\n",
    "    df_game[\"proba\"] = 1 / df_game[\"ltp\"]\n",
    "    \n",
    "    return df_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f0be4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_name = \"Barcelona v Paris St-G\"\n",
    "\n",
    "market_paths = df_metadata[df_metadata[\"event_name\"]==event_name][\"path\"].tolist()\n",
    "\n",
    "data_dict = retrieve_game_data(market_paths)\n",
    "df_game = preprocess_game_data(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "355845de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "x_lim_hours_start_game=(5, 2)\n",
    "date_time_start_game = df_metadata[df_metadata[\"event_name\"]==event_name][\"market_time\"].tolist()[0]\n",
    "\n",
    "\n",
    "def _get_time_filter(\n",
    "    date_time_start_game: str,\n",
    "    x_lim_hours_start_game: Tuple,\n",
    ") -> pd.Series:\n",
    "    min_start_time = (np.datetime64(date_time_start_game) - np.timedelta64(x_lim_hours_start_game[0], 'h'))\n",
    "    max_start_time = (np.datetime64(date_time_start_game) + np.timedelta64(x_lim_hours_start_game[1], 'h'))\n",
    "    return (\n",
    "        (df_proba_per_market[\"publish_time\"] >= min_start_time)\n",
    "        & (df_proba_per_market[\"publish_time\"] <= max_start_time)\n",
    "    )\n",
    "\n",
    "\n",
    "def get_market_liquidity():\n",
    "    return \n",
    "\n",
    "def get_vanilla_arbitrage_frequency(\n",
    "    df_game: pd.DataFrame,\n",
    "    date_time_start_game: str = None,\n",
    "    x_lim_hours_start_game: Tuple = (5, 2),\n",
    "    threshold_arbitrage: float = .02,\n",
    ") -> pd.DataFrame:\n",
    "    # Get time filter\n",
    "    if date_time_start_game and x_lim_hours_start_game:\n",
    "        time_filter = _get_time_filter(date_time_start_game, x_lim_hours_start_game)\n",
    "    else:\n",
    "        time_filter = [True] * df_proba_per_market.shape[0]\n",
    "        \n",
    "    df_proba_per_market = (\n",
    "        df_game[time_filter]\n",
    "        .groupby([\"market_type\", \"market_id\", \"publish_time\"])[\"proba\"].sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    # Compute liquidity statistics\n",
    "    df_nb_ticks = (\n",
    "        df_proba_per_market[time_filter]\n",
    "        .groupby(\"market_type\")[\"market_id\"].count()\n",
    "        .sort_values(ascending=False)\n",
    "        .reset_index()\n",
    "        .rename(columns={\"market_id\": \"nb_ticks\"})\n",
    "    )\n",
    "    max_nb_ticks = df_nb_ticks[\"nb_ticks\"].max()\n",
    "    df_nb_ticks[\"liquidity_pc\"] = df_nb_ticks[\"nb_ticks\"] / max_nb_ticks\n",
    "    \n",
    "    # Compute arbitrage frequency\n",
    "    arbitrage_freq_dict = {\n",
    "        \"market_type\": [],\n",
    "        \"arbitrage_freq\": [],\n",
    "    }\n",
    "    \n",
    "    for market_type in df_nb_ticks[\"market_type\"]:\n",
    "        market_filter = (df_proba_per_market[\"market_type\"] == market_type)\n",
    "\n",
    "        arbitrage_pc = (\n",
    "            sum((df_proba_per_market.loc[market_filter, \"proba\"] - 1).abs() > threshold_arbitrage) / max_nb_ticks\n",
    "        )\n",
    "\n",
    "        arbitrage_freq_dict[\"market_type\"].append(market_type)\n",
    "        arbitrage_freq_dict[\"arbitrage_freq\"].append(arbitrage_pc)\n",
    "    \n",
    "    arbitrage_freq_df = pd.DataFrame(arbitrage_freq_dict)\n",
    "    \n",
    "    return arbitrage_freq_df.merge(df_nb_ticks, on=\"market_type\", how=\"left\").sort_values(\"arbitrage_freq\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd065fbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_proba_per_market' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dt/_d_98phj5tv_55t0dv639x100000gn/T/ipykernel_10488/3477801060.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df_arbitrage = get_vanilla_arbitrage_frequency(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdf_game\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_game\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdate_time_start_game\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_metadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_metadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"event_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"market_time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/dt/_d_98phj5tv_55t0dv639x100000gn/T/ipykernel_10488/3925641916.py\u001b[0m in \u001b[0;36mget_vanilla_arbitrage_frequency\u001b[0;34m(df_game, date_time_start_game, x_lim_hours_start_game, threshold_arbitrage)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Get time filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdate_time_start_game\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx_lim_hours_start_game\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtime_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_time_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_time_start_game\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_lim_hours_start_game\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtime_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdf_proba_per_market\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/dt/_d_98phj5tv_55t0dv639x100000gn/T/ipykernel_10488/3925641916.py\u001b[0m in \u001b[0;36m_get_time_filter\u001b[0;34m(date_time_start_game, x_lim_hours_start_game)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmax_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_time_start_game\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_lim_hours_start_game\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     return (\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mdf_proba_per_market\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"publish_time\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmin_start_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_proba_per_market\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"publish_time\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax_start_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_proba_per_market' is not defined"
     ]
    }
   ],
   "source": [
    "df_arbitrage = get_vanilla_arbitrage_frequency(\n",
    "    df_game=df_game,\n",
    "    date_time_start_game=df_metadata[df_metadata[\"event_name\"]==event_name][\"market_time\"].tolist()[0],\n",
    ")\n",
    "\n",
    "df_arbitrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f9ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_scores_under_i_goals(nb_goals_max):\n",
    "    return [f\"{i} - {k}\" for i in range(0, nb_goals_max+1) for k in range(0, nb_goals_max-i+1)]\n",
    "\n",
    "\n",
    "def get_arbitrage_under_score(df_game) -> pd.DataFrame:\n",
    "    # Get time filter\n",
    "    if date_time_start_game and x_lim_hours_start_game:\n",
    "        time_filter = (\n",
    "            (df_proba_per_market[\"publish_time\"] >= (np.datetime64(date_time_start_game) - np.timedelta64(x_lim_hours_start_game[0], 'h')))\n",
    "            & (df_proba_per_market[\"publish_time\"] <= (np.datetime64(date_time_start_game) + np.timedelta64(x_lim_hours_start_game[1], 'h')))\n",
    "        )\n",
    "    else:\n",
    "        time_filter = [True] * df_proba_per_market.shape[0]\n",
    "    \n",
    "    # Compute arbitrage frequency\n",
    "    arbitrage_freq_dict = {\n",
    "        \"market_type\": [],\n",
    "        \"arbitrage_freq\": [],\n",
    "    }\n",
    "    \n",
    "    for i in range(0, 9):\n",
    "        df_game[\"tmp_arbitrage_group\"] = np.where(\n",
    "            ((df_game[\"market_type\"] == f\"OVER_UNDER_{i}5\") & (df_game[\"runner_name\"] == f\"Under {i}.5 Goals\")) |\n",
    "            ((df_game[\"market_type\"] == \"CORRECT_SCORE\") & ~df_game[\"runner_name\"].isin(get_all_scores_under_i_goals(i))),\n",
    "            1, np.nan\n",
    "        )\n",
    "\n",
    "        df_proba_per_market = (\n",
    "            df_game[df_game[\"tmp_arbitrage_group\"]==1]\n",
    "            .groupby([\"publish_time\"])[\"proba\"].sum()\n",
    "            .reset_index()\n",
    "        )\n",
    "        \n",
    "        arbitrage_pc = (\n",
    "            sum((df_proba_per_market.loc[time_filter, \"proba\"] - 1).abs() > threshold_arbitrage) / max_nb_ticks\n",
    "        )\n",
    "        \n",
    "\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04cf495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arbitrage.plot.scatter(x=\"liquidity_pc\", y=\"arbitrage_freq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29cc897",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arbitrage.sort_values(\"liquidity_pc\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e088c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba_per_market.groupby(\"market_type\")[\"market_type\"].count().sort_values(ascending=False).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaffe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba_per_market[df_proba_filter].plot(x=\"publish_time\", y=\"proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac0e514",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba_per_market[df_proba_filter] > 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
